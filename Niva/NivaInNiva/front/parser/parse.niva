type Parser
  tokens: List::Token
  current: Int 
  statements: mut List::Statement

constructor Parser newParseTokens::List::Token = [
  statements::mut List::Statement = {}!
  parser2:: mut Parser = Parser tokens: newParseTokens current: 0 statements: statements // {}! error TODO
  
  [ parser2 done not ] whileTrue: [
    parser2 statements add: parser2 nextStatement
  ]

  // parser statements debug

  ^ parser2
]


type TypeField name: String type_: AstType2
TypeField toString -> String =  "$name: $type_"

extend mut Parser [
  // maybe collections are missing
  on isLiteralExpr: tok::Token -> Boolean = [ 
   ^| tok kind
    | TokenType.Integer
    | TokenType.String 
    | TokenType.True|TokenType.False
    | TokenType.Char 
    | TokenType.Float 
    | TokenType.Double
    | TokenType.Null => true
    |=> false
  ]

  on parseReturnExpr: tok::Token -> ReturnStatement = [
    tok kind == TokenType.Return ifFalse: [TO DO: "^ expected"]

    // is that `^ value` or just `^`
    savePosition = current
    isThereAValue = (.primary: .peek) != null
    .restoreFrom: savePosition

    value = isThereAValue ifTrue: [.nextExperssion: .step] ifFalse: [null]

    result = ReturnStatement value: value token: tok
    ^ result
  ]

  /// "", 1, 1.1, true, []
  on literalExprFrom: tok::Token -> LiteralExpr? = [
    mut isAdded = false

   ^| tok kind
    | TokenType.Integer => 
      IntExpr num: tok lexeme toInt token: tok
    
    | TokenType.String => 
      StringExpr token: tok
    
    | TokenType.True|TokenType.False => 
      BooleanExpr token: tok
    
    | TokenType.Char => 
      CharExpr token: tok
    
    | TokenType.Float => 
      FloatExpr token: tok
    
    | TokenType.Double => 
      DoubleExpr token: tok
    
    | TokenType.Null => 
      NullExpr token: tok
    
    |=> [null]
  ]

  /// if starts from { #{ #(, then return collection
  /// tok already eaten outside
  on parseCollection: tok::Token -> CollectionLiteral? = [

    manyPrimary = [
      body::mut List::Expr = {}!

      mut c = true
      [c] whileTrue: [
        tok2 = .step
        pr = .primary: tok2
        | pr
        | null => [
          c <- false
        ]
        |=> [
          body add: pr
          .match: TokenType.Comma
          Unit
        ]
      ]
      body
    ]

   ^| tok kind
    | TokenType.OpenBrace => [
      body = manyPrimary do
      .match: TokenType.CloseBrace
      ListLiteral token: tok elements: body
    ]
    | TokenType.OpenBraceHash => [
      body = manyPrimary do
      .match: TokenType.CloseBrace

      body count % 2 != 0 ifTrue: [
        TO DO: "elements count in Map should be even"
      ]

      MapLiteral token: tok elements: body
    ]
    | TokenType.OpenParenHash => [
      body = manyPrimary do
      .match: TokenType.CloseParen
      SetLiteral token: tok elements: body
    ]
    |=> null 
  ]

  
  /// collection {} #{} #()
  /// lambda
  /// or identifier | nullableIdentifier 
  /// simple literal 1 "" '' true false 1.1 1.1f
  on primary: tok::Token -> Expr? = [
    
    .literalExprFrom: tok, unpack: [
      ^it
    ]

    tok isNullOrIdentifier ifTrue: [
      ^ Identifier name: tok lexeme token: tok
    ]

    .parseCollection: tok, unpack: [
      ^it
    ]

    tok kind == TokenType.OpenBracket ifTrue: [
      ^ .parseCodeBlock: tok
    ]

    ^ null
  ]

  // `[` already eaten
  on parseCodeBlock: tok::Token -> CodeBlock = [
    mut args:: List::NameAndAstType = {}   // [a::Int -> a inc]
    mut untypedArgs:: List::Identifier = {} // [a, b -> a + b]

    savePoint = current

    | .peek kind
    | TokenType.IdentifierDoubleColon => [
      identsWithAst = .parseNameDoubleColonAstTypePair: .step separatedBy: TokenType.Comma
      args <- identsWithAst
    ] 
    | TokenType.Identifier => [
      idents = .parseManyIdentSeparated: TokenType.Comma
      untypedArgs <- idents
    ]
    |=> [] 

    wasArrow = .match: TokenType.ReturnArrow

    wasArrow not && untypedArgs isNotEmpty ifTrue: [
      // what if [a + b]
      // a is in untyped args, and body failing with + b
      // so restore
      .restoreFrom: savePoint
      untypedArgs <- {}
    ]

    // wait, just check if there was an arrow, if not, then restore from tok
    mut body = .parseManyExprUntilTok: TokenType.CloseBracket

    result = CodeBlock 
      args: args 
      untypedArgs: untypedArgs
      body: body 
      token: tok
    
    ^ result
  ]


  on parseManyExprUntilTok: until::TokenType -> List::Expr = [
    body::mut List::Expr = {}!

    mut c = true
    [c] whileTrue: [
      tok = .peek
      tok kind == until ifTrue: [
        .step // skip 
        c <- false
      ] ifFalse: [
        // parse statement
        nextTok = .step 
        statement = .nextExperssion: nextTok
        body add: statement
        Unit
      ]
    ]

    ^ body
  ]

  on parseBodyOrSingleExpr -> List::Expr = [
    // tokens map: [it kind toString + "\t\t" + it lexeme], joinWith: "\n"
    ^ .match: TokenType.OpenBracket, ifTrue: [
      // parse body
      .parseManyExprUntilTok: TokenType.CloseBracket
    ] ifFalse: [
      // single expression
      {(.nextExperssion: .step)}
    ]
  ]

  /// a::Int (sep)? b::String
  on parseNameDoubleColonAstTypePair: tok::Token separatedBy: sep::TokenType? -> List::NameAndAstType = [
    
    firstArg = NameAndAstType name: tok lexeme astType: .parseType
    sep unpack: [.match: it]

    kwArgs = {firstArg}!

    mut c = true 
    [c] whileTrue: [
      tok = .peek
      tok kind == TokenType.IdentifierDoubleColon ifTrue: [
        arg = NameAndAstType name: .step lexeme astType: .parseType
        sep unpack: [.match: it]

        kwArgs add: arg
        Unit
      ] ifFalse: [
        c <- false
      ]
    ]
      
    ^ kwArgs
  ]

  on restoreFrom: position::Int = [
    current <- position
  ]

  on skipComments = [
    [.peek kind == TokenType.Comment] whileTrue: [
      .step
    ]
  ]

  on nextStatement -> Statement = [
    // .skipComments
    savePosition = current

    // there always EndOfFile, so this never happen
    tokens isEmpty ifTrue: [TO DO: "no tokens, file is empty"] 
    tok = .step

    // optimization for expr that starts from 1 | ""
    .isLiteralExpr: tok, ifTrue: [
      ^ .nextExperssion: tok
    ]

    | tok kind
    | TokenType.Type => [^ .typeDeclaration: tok]
    | TokenType.Union => [^ .unionTypeDeclaration: tok]
    | TokenType.Identifier => [
      getReturnType = [
        .match: TokenType.ReturnArrow, ifTrue: [
          .parseType
        ] ifFalse: [null]
      ]

      // change current position back to parse receiver
      .stepBack
      receiverType = .parseType

      // Int^ inc =
      // Int^ a::Int b::Int =
      // Int^ a: q::Int b::Int =
      // Int^ + a::Int =
      tok2 = .step
      result = | tok2 kind
      | TokenType.Identifier => [
        // Int inc^ ->? = []
        
        returnType = getReturnType do 
        name = tok2 lexeme

        // .matchAssert: TokenType.Assign
        .match: TokenType.Assign, ifFalse: [
          .restoreFrom: savePosition
          ^ .nextExperssion: .step
        ]
        // Int inc ->? = ^[]

        body = .parseBodyOrSingleExpr

        msgDecl = MessageDecl 
          receiver: receiverType
          name: name
          args: {}
          returnType: returnType
          token: tok
          body: body        

        // statements add: msgDecl
        msgDecl
      ]
      | TokenType.IdentifierDoubleColon => [
        // Int inc^::Int b::Int =
        
        kwArgs = .parseNameDoubleColonAstTypePair: tok2 separatedBy: null

        returnType = getReturnType do 
        name = tok2 lexeme
        
        .matchAssert: TokenType.Assign
        // Int a::Int b::Int ->? = ^[]

        body = .parseBodyOrSingleExpr

        msgDecl = MessageDecl 
          receiver: receiverType
          name: name
          args: kwArgs toList//{(NameAndAstType name: arg lexeme astType: argType)}
          returnType: returnType
          token: tok
          body: body 
        msgDecl
      ]
      | TokenType.BinarySymbol => [
        // Int +^ a::Int -> Int=

        // if its not binary declaration then parse expression
        arg = .step
        arg kind == TokenType.IdentifierDoubleColon, ifFalse: [
          .restoreFrom: savePosition
          ^.nextExperssion: .step
        ]
        argType = .parseType


        returnType = getReturnType do 
        name = tok2 lexeme
        
        .matchAssert: TokenType.Assign
        // Int inc ->? = ^[]

        body = .parseBodyOrSingleExpr

        msgDecl = MessageDecl 
          receiver: receiverType
          name: name
          args: {(NameAndAstType name: arg lexeme astType: argType)}
          returnType: returnType
          token: tok
          body: body        

        // statements add: msgDecl
        msgDecl
      ]
      |=> [
        .restoreFrom: savePosition
        ^.nextExperssion: .step
      ]

      ^ result
    ]
    | TokenType.Return => [
      .parseReturnExpr: tok
    ]
    // commented since expression after is possible
    // | TokenType .OpenBracket => [
    //   ^.parseCodeBlock: tok
    // ]
    | TokenType.EndOfFile => [
      TO DO: "its impossible to be here, whileTrue from top stack goes until `done`"
    ]
    | TokenType.Invalid => [
      prev = .peekAt: -2
      prevPrev = .peekAt: -1
      cur = .peek
      TO DO: "Got invalid token after $prev $prevPrev $cur"

    ]

    |=> [
      "Warning: Parser: fallback to expr parsing with tok: $tok" echo
      ^ .nextExperssion: tok
    ]

    

    .peek kind != TokenType.EndOfFile, ifTrue: [
      .step // just to evade infinity loop
    ]

    

    ^ TO DO: "top level $tok is not allowed"
  ]

  /// `^ expr` | `expr`
  on nextExperssion: tok::Token -> Expr = [
    // return expr
   ^| tok kind 
    | TokenType.Return => .parseReturnExpr: tok
    |=> [
      // message expr
      primaryReceiver = .primary: tok, unpackOrMsg: "nextExperssion: no primary ($tok)"
      firstExpr = .nextExperssion2: tok receiver: primaryReceiver

     ^| .peek kind
      | TokenType.Comma => [
        .step // skip comma
        .nextExperssion2: tok receiver: (ExprInBrackets value: firstExpr token: tok)
      ]
      |=> firstExpr
    ]
  ]

  on nextExperssion2: tok::Token receiver::Expr? -> Expr = [
    // return expr
    tok kind == TokenType.Return ifTrue: [
      ^ .parseReturnExpr: tok
    ]
    // message expr
    primaryUnaryBinary = .parsePrimaryOrUnaryOrBinary: tok receiver: receiver

    ^| .peek kind
    | TokenType.IdentifierColon => [

      result::mut List::NameAndExpr = {}!
      mut c = true
      // parse keyword
      [c] whileTrue: [
        colon = .peek
        | colon kind
        | TokenType.IdentifierColon => [

          result add: 
            (NameAndExpr 
              name: (Identifier fromToken: .step) 
              expr: (.parsePrimaryOrUnaryOrBinary: .step))
          Unit
  
        ]
        |=> [
          c <- false
        ]
      ]
      // current debug
      
      KeywordMsg 
        args: result toList
        receiver: primaryUnaryBinary
        token: tok
    ]
    |=> primaryUnaryBinary
  ]


  // returns
  // Primary
  // UnaryMsg
  // BinaryMsg
  on parsePrimaryOrUnaryOrBinary: tok::Token -> Expr = .parsePrimaryOrUnaryOrBinary: tok receiver: null
  on parsePrimaryOrUnaryOrBinary: tok::Token receiver::Expr? -> Expr = [
    maybePrimary = | receiver 
    | null => .primary: tok, unpackOrMsg: "nextExperssion: no primary ($tok)"
    |=> receiver

    next = .peek
    // single primary before new line
    // or in other words just `42`
    next line > tok line, ifTrue: [
      ^ maybePrimary
    ]

    // 1 ^
    
    | next kind
    // 1 ^inc 
    | TokenType.Identifier => [
      // primary identifier

      // msg = MessageSend args: List::NameAndExpr token: next
      // while there are identifiers - parse and save them, its a begining of unary     
      tok = .peek
      | tok kind 
      | TokenType.Identifier => [
        unaryIdentifiers = .parseManyIdentSeparated: null
        // 1 inc inc^
        unary = UnaryMsg 
          args: unaryIdentifiers toList 
          receiver: maybePrimary 
          token: maybePrimary token
        
        .peek kind == TokenType.BinarySymbol, ifTrue: [
          // 1 inc inc^ + 2
          binaryList = .parseManyBinary
          binary = BinaryMsg 
            args: binaryList toList 
            receiver: unary
            token: maybePrimary token
          .peek kind == TokenType.IdentifierColon, ifTrue: [
            // 1 inc from: 2
            TO DO: "parse keyword after binary2"
          ]
          ^binary
        ]

        // .peek kind == TokenType.IdentifierColon, ifTrue: [
        //   // 1 inc from: 2
        //   TO DO: "parse keyword after unary"
        // ]
        ^ unary
        Unit
      ]
      | TokenType.BinarySymbol => [
        binaryList = .parseManyBinary
        
        binary = BinaryMsg 
          args: binaryList toList 
          receiver: maybePrimary 
          token: maybePrimary token
        // statements add: binary
        // TODO нужно трекать уровень вложенности, и если вложенность больше 0, то не добавлять
        // .peek kind == TokenType.IdentifierColon, ifTrue: [
        //   // 1 inc from: 2
        //   TO DO: "parse keyword after binary1"
        // ]
        ^ binary
        Unit
      ]
      |=> [
        Unit
      ]
      
      TO DO: "parse unary"
    ]
    | TokenType.BinarySymbol => [
      // primary binary
      // 1 + 1 + 1
      // 1 + 1 sas: 2


      // 1 + ^2
      binaryList = .parseManyBinary
      
      binary = BinaryMsg 
        args: binaryList 
        receiver: maybePrimary 
        token: maybePrimary token
      // statements add: binary

      // .peek kind == TokenType.IdentifierColon, ifTrue: [
      //   TO DO: "binary is a receiver for keyword"
      // ]

      ^ binary
      // kw possible
    
      // if while parsing binary got keyword than continue keyword parsing
    ]
    // | TokenType.IdentifierColon => [
    //   // primary keyword
    //   // 1 from: 2
    //   // 1 inc from: 2      
    //   // 1 + 1 from: 2
    //   // binaryList = .parseManyBinary
    //   // binaryList debug
    //   TO DO: "parse simple keyword1"
    // ]
    |=> []

    ^ maybePrimary
  ]



  // / x| probably not just identifier without anything
  // / x = ...
  // / x inc ...
  // / X inc = []
  // / x + ...
  // / X + y::Int = []
  // / x that: ...
  // / X from::Int = []
  // / X from y:Int = []



  on match::TokenType -> Boolean = [
    .peek kind == match, ifTrue: [
      .step
      ^ true
    ]

    ^ false
  ]

  /// match Identifier|Nullable|Error
  on matchAssertAnyIdent: error::String -> Token = [
    tok = .peek

    ^ tok isIdentifier ifTrue: [
      .step
      tok
    ] ifFalse: [
      TO DO: error
    ]
  ]

  on parseNullOrIdentifier -> Identifier? = [
    tok = .peek
    ^ tok isNullOrIdentifier ifTrue: [
      .step
      Identifier name: tok lexeme token: tok
    ] ifFalse: [
      null
    ]
  ]

  on matchAssert::TokenType -> Token = [
    peek = .peek
    peek kind == matchAssert, ifTrue: [
      ^ .step
    ]
    kind = peek kind
    TO DO: "$matchAssert expected but got $peek"
  ]

  on matchString::String -> Boolean = [
    .peek lexeme == matchString, ifTrue: [
      .step
      ^ true
    ]

    ^ false
  ]

  on check: kind::TokenType = .peek kind == kind

  on done = .check: TokenType.EndOfFile

  on step -> Token = [
    x = .peek
    x kind == TokenType.EndOfFile, ifTrue: [
      TO DO: "step: EOF"
    ]
    current <- current inc
    ^ x
  ]
  on stepBack -> Token = [
    x = .peekAt: -1
    current <- current dec
    ^ x
  ]

  /// if current is out of bounds returns EOF
  /// otherwise returns token at current position
  on peek -> Token = [
    // current >= tokens count, ifTrue: [
    //   ^ Token eof
    // ]

    ^tokens at: current
  ]
  on peekAt: distance::Int -> Token = [
    realDistance = current + distance
    ^tokens at: realDistance
  ]
]
