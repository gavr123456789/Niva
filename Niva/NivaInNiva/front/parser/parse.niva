type Parser
  tokens: List::Token
  current: Int 
  statements: MutableList::Statement

constructor Parser newParseTokens::List::Token = [
  statements::MutableList::Statement = {}m
  parser:: mut Parser = Parser tokens: newParseTokens current: 0 statements: statements // {}m error TODO
  [ parser done not ] whileTrue: [
    parser nextStatement 
  ]

  ^ parser
]


type TypeField name: String type_: AstType

extend mut Parser [
  /// if literal was added returns true
  on literalExprFrom: tok::Token -> Boolean = [
    mut isAdded = false
    addLiteral = [ lit::LiteralExpr ->
      // .step
      statements add: (lit)
      isAdded <- true
      Unit
    ]

    | tok kind
    | TokenType.Integer => [
      num = tok lexeme toInt
      addLiteral lit: (IntExpr num: num token: tok)
    ]
    | TokenType.String => 
      addLiteral lit: (StringExpr token: tok)
    
    | TokenType.True|TokenType.False => 
      addLiteral lit: (BooleanExpr token: tok)
    
    | TokenType.Char => 
      addLiteral lit: (CharExpr token: tok)
    
    | TokenType.Float => 
      addLiteral lit: (FloatExpr token: tok)
    
    | TokenType.Double => 
      addLiteral lit: (DoubleExpr token: tok)
    
    | TokenType.Null => 
      addLiteral lit: (NullExpr token: tok)
    
    |=> []
    ^isAdded
  ]

  // List::Set::Int
  // Map(String, Int)
  /// identifier ("(" | "::")
  on parseGenericType -> AstType = [

    identifier = .matchAssertAnyIdent: "in type declaration identifier expected"
    isNullable = identifier kind == TokenType.NullableIdentifier
    name = identifier lexeme

    isListLike = identifier kind == TokenType.IdentifierDoubleColon
    isMapLike = .match: TokenType.OpenParen

    isListLike ifTrue: [
      recursiveGenerics = .parseGenericType
      // errors = .parseErrors
      ^ AstType 
        name: name 
        nullable: isNullable
        genericParams: {recursiveGenerics}

    ]

    isMapLike ifTrue: [
      typeArgumentList::MutableList::AstType = {}m

      mut continue = true 
      [continue] whileTrue: [
        typeArgumentList add: .parseGenericType
        continue <- .match: TokenType.Comma
      ]

      .matchAssert: TokenType.CloseParen
      ^ AstType 
        name: name 
        nullable: isNullable
        genericParams: typeArgumentList toList
    ]

    // no Map() no List::
    ^ AstType 
      name: name 
      nullable: isNullable
      genericParams: {}
  ]
  on parseType -> AstType = [

    isMut = .match: TokenType.Mut
    itLambda = .match: TokenType.OpenBracket, ifTrue: [
      TO DO: "parseLambda"
    ]
    result::mut AstType = .parseGenericType
    result setMutable: isMut
    ^ result
  ]

  /// `name: String`
  on typeFields -> List::TypeField = [
    .peek kind == TokenType.IdentifierColon, assert: "Expected `field:`"
    result::MutableList::TypeField = {}m

    mut c = true
    [c] whileTrue: [
      tok = .peek
      tok kind == TokenType.IdentifierColon ifTrue: [
        .step // skip 

        type_ = .parseType
        type_field = TypeField name: (tok lexeme) type_: type_ // dropLast: 1, ":"
        result add: (type_field)
        // need continue?
        c <- .peek kind == TokenType.IdentifierColon 
      ] ifFalse: [
        c <- false
      ]
    ]

    ^ result toList
  ]

  /// type name (field1: astType)*
  on typeDeclaration: tok::Token = [
    // type name (field1: astType)*

    res = TypeDecl 
      name: (.step lexeme)
      fields: (.typeFields)
      token: tok
    // res debug
    .statements add: res
  ]

  on parseBodyOrSingleExpr -> List::Statement = [
    tokens map: [it kind toString + "\t\t" + it lexeme], joinWith: "\n", debug

    body::MutableList::Statement = {}m

    // TODO refactor so nextStatement will return Statement
    getNextStatement = [
      .nextStatement
      
      statement = statements last
      statements <- statements dropLast: 1, m
      statement
    ]

    .match: TokenType.OpenBracket, ifTrue: [
      // parse body
      mut c = true
      [c] whileTrue: [
        tok = .peek
        tok kind == TokenType.CloseBracket ifTrue: [
          .step // skip 
          c <- false
        ] ifFalse: [
          // parse statement
          statement = getNextStatement do
          body add: statement
          Unit
        ]
      ]
    ] ifFalse: [
      // single expression
      statements count == 0 ifTrue: [
        TO DO: "parseBodyOrSingleExpr: no statement"
      ]

      statement = getNextStatement do
      body add: statement
    ]

    ^ body toList
  ]



  on nextStatement -> Unit = [
    // there always EndOfFile, so this never happen
    tokens isEmpty ifTrue: [^Unit] 
    tok = .step

    // simple literal
    .literalExprFrom: tok, ifTrue: [^Unit]


    | tok kind
    | TokenType.Type => .typeDeclaration: tok
    | TokenType.Identifier => [
      getReturnType = [
        .match: TokenType.ReturnArrow, ifTrue: [
          .parseType
        ] ifFalse: [null]
      ]
      // change current position back to parse type
      .stepBack
      receiverType = .parseType


      // Int^ inc =
      // Int^ a::Int b::Int =
      // Int^ + a::Int =
      tok2 = .step
      | tok2 kind
      | TokenType.Identifier => [
        // Int inc^ ->? = []
        
        returnType = getReturnType do 
        name = tok2 lexeme

        receiverType debug
        returnType echo
        
        .matchAssert: TokenType.Assign
        // Int inc ->? = ^[]

        body = .parseBodyOrSingleExpr

        msgDecl = MessageDecl 
          receiver: receiverType
          name: name
          args: {}
          returnType: returnType
          token: tok
          body: body        

        statements add: msgDecl
        Unit
      ]
      | TokenType.IdentifierDoubleColon => [
        // Int inc^::Int b::Int =

      ]
      | TokenType.BinarySymbol => [
        // Int^ + a::Int =

      ]
      |=> []

      Unit
    ]

    | TokenType.EndOfFile => [
      TO DO: "its impossible to be here, whileTrue from top stack goes until `done`"
      Unit
    ]
    |=> []

    

    .peek kind != TokenType.EndOfFile, ifTrue: [
      .step // just to evade infinity loop
    ]
  ]

  /// x| probably not just identifier without anything
  /// x = ...
  /// x inc ...
  /// X inc = []
  /// x + ...
  /// X + y::Int = []
  /// x that: ...
  /// X from::Int = []
  /// X from y:Int = []
  on identifierStart: tok::Token = [
    TO DO: "identifierStart not impl"
    ident = .step
    next = .step
    
  ]


  on match::TokenType -> Boolean = [
    .peek kind == match, ifTrue: [
      .step
      ^ true
    ]

    ^ false
  ]

  /// match Identifier|Nullable|Error
  on matchAssertAnyIdent: error::String -> Token = [
    tok = .peek

    ^ tok isIdentifier ifTrue: [
      .step
      tok
    ] ifFalse: [
      TO DO: error
    ]
  ]

  on matchAssert::TokenType -> Token = [
    .peek kind == matchAssert, ifTrue: [
      ^ .step
    ]
    TO DO: "$matchAssert expected"
  ]

  on matchString::String -> Boolean = [
    .peek lexeme == matchString, ifTrue: [
      .step
      ^ true
    ]

    ^ false
  ]

  on check: kind::TokenType = .peek kind == kind

  on done = .check: TokenType.EndOfFile

  on step -> Token = [
    x = .peek
    current <- current inc
    ^ x
  ]
  on stepBack -> Token = [
    x = .peekAt: -1
    current <- current dec
    ^ x
  ]
  on peek -> Token = [
    ^tokens at: current
  ]
  on peekAt: distance::Int -> Token = [
    realDistance = current + distance
    ^tokens at: realDistance
  ]
]
