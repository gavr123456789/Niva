type Parser
  tokens: List::Token
  current: Int 
  statements: MutableList::Statement

constructor Parser newParseTokens::List::Token = [
  statements::MutableList::Statement = {}m
  parser:: mut Parser = Parser tokens: newParseTokens current: 0 statements: statements // {}m error TODO
  [ parser done not ] whileTrue: [
    parser nextStatement 
  ]

  parser statements debug

  ^ parser
]


type TypeField name: String type_: AstType

extend mut Parser [
  /// if literal was added returns true
  on literalExprFrom: tok::Token -> LiteralExpr? = [
    mut isAdded = false
    addLiteral = [ lit::LiteralExpr ->
      // .step
      // statements add: (lit)
      lit
    ]

    ^| tok kind
    | TokenType.Integer => [
      num = tok lexeme toInt
      addLiteral lit: (IntExpr num: num token: tok)
    ]
    | TokenType.String => 
      addLiteral lit: (StringExpr token: tok)
    
    | TokenType.True|TokenType.False => 
      addLiteral lit: (BooleanExpr token: tok)
    
    | TokenType.Char => 
      addLiteral lit: (CharExpr token: tok)
    
    | TokenType.Float => 
      addLiteral lit: (FloatExpr token: tok)
    
    | TokenType.Double => 
      addLiteral lit: (DoubleExpr token: tok)
    
    | TokenType.Null => 
      addLiteral lit: (NullExpr token: tok)
    
    |=> [null]
  ]

// TODO
  on parseCollection -> CollectionLiteral? = [
    ^ TO DO: "parseCollection"
    // mut isAdded = false
    // addLiteral = [ lit::LiteralExpr ->
    //   // .step
    //   // statements add: (lit)
    //   lit
    // ]

    // ^| tok kind
    // | TokenType.OpenBracket => [
    //   // parse collection
    //   mut c = true
    //   [c] whileTrue: [
    //     tok = .peek
    //     tok kind == TokenType.CloseBracket ifTrue: [
    //       .step // skip 
    //       c <- false
    //     ] ifFalse: [
    //       // parse statement
    //       statement = .nextExperssion: (.step)
    //       body add: statement
    //       Unit
    //     ]
    //   ]
    // ]
  ]


  /// collection {} #{} #()
  /// or identifier | nullableIdentifier 
  /// simple literal 1 "" '' true false 1.1 1.1f
  on primary::Token -> Expr? = [
    .literalExprFrom: primary, unpack: [
      ^it
    ]

    //collection 
    // .parseCollection, unpack: [
    //   ^it
    // ]

        // identifier 
    .parseNullOrIdentifier, unpack: [
      ^it
    ]

    ^ null
  ]

  // List::Set::Int
  // Map(String, Int)
  /// identifier ("(" | "::")
  on parseGenericType -> AstType = [

    identifier = .matchAssertAnyIdent: "in type declaration identifier expected"
    isNullable = identifier kind == TokenType.NullableIdentifier
    name = identifier lexeme

    isListLike = identifier kind == TokenType.IdentifierDoubleColon
    isMapLike = .match: TokenType.OpenParen

    isListLike ifTrue: [
      recursiveGenerics = .parseGenericType
      // errors = .parseErrors
      ^ AstType 
        name: name 
        nullable: isNullable
        genericParams: {recursiveGenerics}

    ]

    isMapLike ifTrue: [
      typeArgumentList::MutableList::AstType = {}m

      mut continue = true 
      [continue] whileTrue: [
        typeArgumentList add: .parseGenericType
        continue <- .match: TokenType.Comma
      ]

      .matchAssert: TokenType.CloseParen
      ^ AstType 
        name: name 
        nullable: isNullable
        genericParams: typeArgumentList toList
    ]

    // no Map() no List::
    ^ AstType 
      name: name 
      nullable: isNullable
      genericParams: {}
  ]
  on parseType -> AstType = [

    isMut = .match: TokenType.Mut
    itLambda = .match: TokenType.OpenBracket, ifTrue: [
      TO DO: "parseLambda"
    ]
    result::mut AstType = .parseGenericType
    result setMutable: isMut
    ^ result
  ]

  /// `name: String`
  on typeFields -> List::TypeField = [
    .peek kind == TokenType.IdentifierColon, assert: "Expected `field:`"
    result::MutableList::TypeField = {}m

    mut c = true
    [c] whileTrue: [
      tok = .peek
      tok kind == TokenType.IdentifierColon ifTrue: [
        .step // skip 

        type_ = .parseType
        type_field = TypeField name: (tok lexeme) type_: type_ // dropLast: 1, ":"
        result add: (type_field)
        // need continue?
        c <- .peek kind == TokenType.IdentifierColon 
      ] ifFalse: [
        c <- false
      ]
    ]

    ^ result toList
  ]

  /// type name (field1: astType)*
  on typeDeclaration: tok::Token -> Statement = [
    // type name (field1: astType)*

    res = TypeDecl 
      name: (.step lexeme)
      fields: (.typeFields)
      token: tok
    // res debug
    .statements add: res
    ^ res
  ]

  on parseBodyOrSingleExpr -> List::Statement = [
    // tokens map: [it kind toString + "\t\t" + it lexeme], joinWith: "\n"

    body::MutableList::Statement = {}m

    .match: TokenType.OpenBracket, ifTrue: [
      // parse body
      mut c = true
      [c] whileTrue: [
        tok = .peek
        tok kind == TokenType.CloseBracket ifTrue: [
          .step // skip 
          c <- false
        ] ifFalse: [
          // parse statement
          statement = .nextExperssion: (.step)
          body add: statement
          Unit
        ]
      ]
    ] ifFalse: [
      // single expression
      statements count == 0 ifTrue: [
        TO DO: "parseBodyOrSingleExpr: no statement"
      ]

      statement = .nextExperssion: (.step)
      body add: statement
    ]

    ^ body toList
  ]



  on nextStatement -> Statement = [
    // there always EndOfFile, so this never happen
    tokens isEmpty ifTrue: [TO DO: "nextStatement: no tokens"] 
    tok = .step


    | tok kind
    | TokenType.Type => [^ .typeDeclaration: tok]
    | TokenType.Identifier => [
      getReturnType = [
        .match: TokenType.ReturnArrow, ifTrue: [
          .parseType
        ] ifFalse: [null]
      ]


      // change current position back to parse type
      .stepBack
      receiverType = .parseType


      // Int^ inc =
      // Int^ a::Int b::Int =
      // Int^ + a::Int =
      tok2 = .step
      result = | tok2 kind
      | TokenType.Identifier => [
        // Int inc^ ->? = []
        
        returnType = getReturnType do 
        name = tok2 lexeme

        .matchAssert: TokenType.Assign
        // Int inc ->? = ^[]

        body = .parseBodyOrSingleExpr

        msgDecl = MessageDecl 
          receiver: receiverType
          name: name
          args: {}
          returnType: returnType
          token: tok
          body: body        

        statements add: msgDecl
        msgDecl
      ]
      | TokenType.IdentifierDoubleColon => [
        // Int inc^::Int b::Int =
        TO DO: "111"
      ]
      | TokenType.BinarySymbol => [
        // Int +^ a::Int -> Int=

        arg = .matchAssert: TokenType.IdentifierDoubleColon
        argType = .parseType


        returnType = getReturnType do 
        name = tok2 lexeme
        
        .matchAssert: TokenType.Assign
        // Int inc ->? = ^[]

        body = .parseBodyOrSingleExpr

        msgDecl = MessageDecl 
          receiver: receiverType
          name: name
          args: {(NameAndType name: arg lexeme astType: argType)}
          returnType: returnType
          token: tok
          body: body        

        statements add: msgDecl
        msgDecl
      ]
      |=> [TO DO: "222"]

      result debug
      ^ result
      
    ]

    | TokenType.EndOfFile => [
      TO DO: "its impossible to be here, whileTrue from top stack goes until `done`"
    ]
    |=> [
      ^ .nextExperssion: tok
    ]

    

    .peek kind != TokenType.EndOfFile, ifTrue: [
      .step // just to evade infinity loop
    ]
    ///// Expressions
    // simple literal
    

    ^ TO DO: "nextStatement: no statement"
  ]




  on nextExperssion: tok::Token -> Expr = [


    // experiment
    // qx = NameAndExpr name: "345" expr: ast.Expr
  

    // .literalExprFrom: tok, unpack: [^it]
    "nextExperssion: tok" echo
    // .parseNullOrIdentifier: ""
    maybePrimary = .primary: tok, unpackOrPANIC 

    next = .peek 

    | next kind
    | TokenType.Identifier => [
      // primary identifier

      first = Identifier name: (next lexeme) token: next

      // msg = MessageSend args: List::NameAndExpr token: next
      // while there are identifiers - parse and save them, its a begining of unary     
      tok = .peek

      | tok kind 
      | TokenType.Identifier => [
        unaryIdentifiers = .parseManyIdent
        unaryIdentifiers debug
        unary = UnaryMsg 
          args: unaryIdentifiers toList 
          receiver: maybePrimary 
          token: maybePrimary token
        
        .peek kind == TokenType.BinarySymbol, ifTrue: [
          binaryList = .parseManyBinary
          binary = BinaryMsg 
            args: binaryList toList 
            receiver: unary
            token: maybePrimary token
          statements add: binary
          ^binary
        ]
        statements add: unary
        "!!!!" echo
        ^ unary
        Unit
      ]
      | TokenType.BinarySymbol => [
        binaryList = .parseManyBinary
        binaryList debug 
        
        binary = BinaryMsg 
          args: binaryList toList 
          receiver: maybePrimary 
          token: maybePrimary token
        statements add: binary
        ^ binary
        Unit
      ]
      |=> [
        Unit
      ]
      
      // if while parsing unary got binary than continue binary parsing

      // if while parsing unary got keyword than continue keyword parsing


      TO DO: "parse unary"
    ]
    | TokenType.BinarySymbol => [
      // primary binary
      // 1 + 1 + 1
      // 1 + 1 sas: 2


      // 1 + ^2
      // receiver = .primary: .step
      // receiver debug
      binaryList = .parseManyBinary
      binaryList debug
      
      binary = BinaryMsg 
        args: binaryList 
        receiver: maybePrimary 
        token: maybePrimary token
      statements add: binary

      .peek kind == TokenType.IdentifierColon, ifTrue: [
        TO DO: "binary is a receiver for keyword"
      ]

      ^ binary
      // kw possible
    
      // if while parsing binary got keyword than continue keyword parsing
    ]
    | TokenType.Colon => [
      // primary keyword
      // 1 inc: 2
      // 1 inc: 2 inc: 3
      // 1 inc: 2 inc: 3 that: 4
      TO DO: "parse keyword"

    ]
    |=> []

    ^ TO DO: "nextExperssion: no statement"
  ]



  // / x| probably not just identifier without anything
  // / x = ...
  // / x inc ...
  // / X inc = []
  // / x + ...
  // / X + y::Int = []
  // / x that: ...
  // / X from::Int = []
  // / X from y:Int = []



  on match::TokenType -> Boolean = [
    .peek kind == match, ifTrue: [
      .step
      ^ true
    ]

    ^ false
  ]

  /// match Identifier|Nullable|Error
  on matchAssertAnyIdent: error::String -> Token = [
    tok = .peek

    ^ tok isIdentifier ifTrue: [
      .step
      tok
    ] ifFalse: [
      TO DO: error
    ]
  ]

  on parseNullOrIdentifier -> Identifier? = [
    tok = .peek

    ^ tok isNullOrIdentifier ifTrue: [
      .step
      Identifier name: tok lexeme token: tok
    ] ifFalse: [
      null
    ]
  ]

  on matchAssert::TokenType -> Token = [
    .peek kind == matchAssert, ifTrue: [
      ^ .step
    ]
    TO DO: "$matchAssert expected"
  ]

  on matchString::String -> Boolean = [
    .peek lexeme == matchString, ifTrue: [
      .step
      ^ true
    ]

    ^ false
  ]

  on check: kind::TokenType = .peek kind == kind

  on done = .check: TokenType.EndOfFile

  on step -> Token = [
    x = .peek
    current <- current inc
    ^ x
  ]
  on stepBack -> Token = [
    x = .peekAt: -1
    current <- current dec
    ^ x
  ]
  on peek -> Token = [
    ^tokens at: current
  ]
  on peekAt: distance::Int -> Token = [
    realDistance = current + distance
    ^tokens at: realDistance
  ]
]
