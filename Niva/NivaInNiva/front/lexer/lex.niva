
/// abcd
/// __^
/// pos = 2, 
/// readPos = 3, because it one step ahead
/// ch = 'c'
type Lexer
  input: String
  pos: Int // updates when new token read
  readPos: Int // updates every step
  ch: Char
  line: Int
  posOnLine: Int

constructor Lexer input::String = [
  l::mut Lexer = Lexer input: input pos: 0 readPos: 0 ch: '\u0000' line: 1 posOnLine: 0
  l step 
  ^l 
] 

constructor Lexer newLex: input::String -> List::Token = [
  ^ Lexer input: input, lex toList
] 

extend mut Lexer [
  on printState = [
    "---" echo
    // input debug
    // readPos debug
    ch debug
    posOnLine debug
    line debug
    "---" echo
  ]

  on printFullState = [
    "---" echo
    // input debug
    input echo
    posOnLine repeat: [
      " " echonnl
    ]
    "^" echo

    ch debug
    posOnLine debug
    "---" echo
  ]


  on step = [
    readPos >= input count 
      ifTrue: [ch <- '\u0000'] 
      ifFalse: [ch <- input at: readPos] 
      
    readPos >= 200 => Error throwWithMessage: "readPos >= 200, $readPos", orPANIC
    pos       <- readPos
    readPos   <- readPos inc
    posOnLine <- posOnLine inc // resets to 0 on \n
  ]

  on peekChar = readPos == input count 
    ifTrue:  ['\u0000']
    ifFalse: [input at: (.readPos)]
  
  on match: char::Char -> Boolean = 
    .ch == char 
      ifTrue: [
        .step
        true
      ] ifFalse: [
        false
      ]
  
  on stepMatch: char::Char -> Boolean = [
    // input count debug
    .step 
    ^.match: char
  ]

  on createToken: kind::TokenType lexeme::String -> Token = [
    // posOnLine - lexeme count, debug
    // posOnLine debug
    // line debug
    tok = Token
      kind: kind
      lexeme: lexeme
      line: line
      start: posOnLine - lexeme count end: posOnLine//lexeme count
    
    // tok debug
    pos <- readPos
    ^ tok
  ]

  on nextToken -> Token! = [
    .skipWhiteSpaces

    l = ch toString

    tok = | ch 
    | '\u0000' => [
      ^.createToken: TokenType.EndOfFile lexeme: l]
    | '=' => [
      .step
      | ch 
      | '=' => .createToken: TokenType.BinarySymbol lexeme: "=="
      | '>' => .createToken: TokenType.Then lexeme: "=>"
      |=> .createToken: TokenType.Assign lexeme: "="
    ]

    | '|' => [
      .step
      | ch 
      | '=' => [
        .step 
        | ch
        | '>' => .createToken: TokenType.Else lexeme: "|=>"
        |=> Error throwWithMessage: "expected |=>"
      ]
      | '|' => .createToken: TokenType.BinarySymbol lexeme: "||"
      |=> .createToken: TokenType.If lexeme: "|"
    ]

    | '"' => [
      result = .parseStringLike: '"'
      ^ .createToken: TokenType.String lexeme: result
    ]
    | '\'' => [
      result = .parseStringLike: '\'' 
      ^ .createToken: TokenType.String lexeme: result
    ]
    | '/' => .stepMatch: '/', 
      ifTrue:  [
        .skipCurrentLine
        .createToken: TokenType.Comment lexeme: "//"
      ] 
      ifFalse: [.createToken: TokenType.BinarySymbol lexeme: "/"]

    | '!' => .stepMatch: '=', 
      ifTrue:  [.createToken: TokenType.BinarySymbol lexeme: "!="] 
      ifFalse: [.createToken: TokenType.Bang lexeme: "!"]
    | '&' => .stepMatch: '&', 
      ifTrue:  [.createToken: TokenType.BinarySymbol lexeme: "&&"] 
      ifFalse: [.createToken: TokenType.Ampersand lexeme: "&"]

    // parens
    | '(' => .createToken: TokenType.OpenParen   lexeme: l
    | ')' => .createToken: TokenType.CloseParen  lexeme: l
    | '[' => .createToken: TokenType.OpenBracket   lexeme: l
    | ']' => .createToken: TokenType.CloseBracket  lexeme: l
    | '{' => .createToken: TokenType.OpenBrace   lexeme: l
    | '}' => .createToken: TokenType.CloseBrace  lexeme: l
    | '#' => [
      .step
      | ch 
      | '{' => .createToken: TokenType.OpenBraceHash lexeme: "#{"
      | '(' => .createToken: TokenType.OpenParenHash lexeme: "#("
      |=> Error throwWithMessage: "only { or ( can be after #"
    ]

    // binary symbols
    |'-' => .stepMatch: '>', 
      ifTrue:  [.createToken: TokenType.ReturnArrow lexeme: "->"] 
      ifFalse: [.createToken: TokenType.BinarySymbol lexeme: "-"]

    |'<' => .stepMatch: '=', 
      ifTrue:  [.createToken: TokenType.BinarySymbol lexeme: "<="] 
      ifFalse: [.createToken: TokenType.Bang lexeme: "<"]

    |'>' => .stepMatch: '=', 
      ifTrue:  [.createToken: TokenType.BinarySymbol lexeme: ">="] 
      ifFalse: [.createToken: TokenType.Bang lexeme: ">"]

    
    |'+'|'*' => .createToken: TokenType.BinarySymbol lexeme: l
    // other staff
    | ',' =>     .createToken: TokenType.Comma lexeme: l
    | '^' => .createToken: TokenType.Return  lexeme: l
    
    |=> [
      // identifier
      ch isLetter || (ch == '_') ifTrue: [
        pos == readPos ifTrue: [
          pos <- pos dec
        ]
        lit = .readIdentifier
        tt = Token lookupKeyword: lit

        // digit after identifier "sas42"
        ch isDigit ifTrue: [
          litDigit = .parseNumber
          ^ .createToken: TokenType.Identifier lexeme: lit + litDigit
        ]

        // colon after identifier

        ^| ch 
        | ':' => [
          .step
          | ch 
          | ':' => [
            .step
            .createToken: TokenType.IdentifierDoubleColon lexeme: lit
          ]
          |=> .createToken: TokenType.IdentifierColon lexeme: lit 
        ] 
        | '?' => [
          .step
          .createToken: TokenType.NullableIdentifier lexeme: lit
        ]
        |=> [
          .createToken: tt lexeme: lit
        ]
      ]
      // digit
      ch isDigit ifTrue: [
        lit = .parseNumber
        ^ .createToken: TokenType.Integer lexeme: lit
      ]
      
      // fail
      .createToken: TokenType.Invalid lexeme: l
    ]

    .step
    ^ tok
  ]

  on lex -> mut List::Token! = [
    mut newTok = .nextToken
    mut tokens::mut List::Token = {newTok}!

    [newTok kind != TokenType.EndOfFile] whileTrue: [
      newTok <- .nextToken
      tokens add: newTok
    ]
    ^ tokens
  ]
  /// skips any symbol until "\n"
  on skipCurrentLine = [
    [(ch != '\n') && (ch != '\u0000')] whileTrue: [
      // "'$ch'" echo
      .step
    ]
    .match: '\n'
  ]
]


enum StrMode = Single | Multi

/// assume that delimiter was already eaten
mut Lexer parseStringLike: delimiter::Char -> String = [
  mut mode = StrMode.Single
  localPos = pos

  .match: delimiter // eat the first "
  [ch != delimiter] whileTrue: [
    ch == '\n' ifTrue: [mode <- StrMode.Multi]
    .step
  ]
  .match: delimiter // eat the last "
  
  ^ input slice: localPos..<pos
]

mut Lexer readIdentifier -> String = [
  localPos = pos
  
  [ch isLetter] whileTrue: [
    .step
  ]

  result = input slice: localPos..<pos //readPos dec
  ^result
]

mut Lexer parseNumber -> String = [
  localPos = pos 
  [ch isDigit] whileTrue: [
    .step
  ]

  result = input slice: localPos..<pos // readPos dec
  ^result
]

mut Lexer skipWhiteSpaces = [
  [(ch == ' ') || (ch == '\t') || (ch == '\n') || (ch == '\r')] whileTrue: [

    ch == '\n' ifTrue: [
      line <- line inc
      posOnLine <- 0 
    ]
    .step
    
  ]
 
]
