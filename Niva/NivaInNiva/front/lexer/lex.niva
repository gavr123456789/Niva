
/// abcd
/// __^
/// pos = 2,
/// readPos = 3, because it one step ahead
/// ch = 'c'
type Lexer
  input: String
  pos: Int // updates when new token read
  readPos: Int // updates every step
  ch: Char
  line: Int
  posOnLine: Int

constructor Lexer input: String = [
  l::mut Lexer = Lexer input: input pos: 0 readPos: 0 ch: '\u0000' line: 1 posOnLine: 0
  l step
  ^l
]

constructor Lexer newLex(input): String -> List::Token = [
  ^ Lexer input: input, lex toList
]

extend mut Lexer [
  on printState = [
    "---" echo
    // input debug
    // readPos debug
    ch debug
    posOnLine debug
    line debug
    "---" echo
  ]

  on printFullState = [
    "---" echo
    // input debug
    input echo
    posOnLine repeat: [
      " " echonnl
    ]
    "^" echo

    ch debug
    posOnLine debug
    "---" echo
  ]


  on step = [
    readPos >= input count
      ifTrue: [ch <- '\u0000']
      ifFalse: [ch <- input at: readPos]

    readPos >= 1000 => Error throwWithMessage: "readPos >= 1000, $readPos", orPANIC
    pos       <- readPos
    readPos   <- readPos inc
    posOnLine <- posOnLine inc // resets to 0 on \n
  ]

  on peekChar = readPos == input count
    ifTrue:  ['\u0000']
    ifFalse: [input at: (.readPos)]

  on match(char): Char -> Bool =
    .ch == char
      ifTrue: [
        .step
        true
      ] ifFalse: [
        false
      ]

  on stepMatch(char): Char -> Bool = [
    // input count debug
    .step
    ^.match: char
  ]

  on createToken(kind): TokenType lexeme: String -> Token = [
    // posOnLine - lexeme count, debug
    // posOnLine debug
    // line debug
    tok = Token
      kind: kind
      lexeme: lexeme
      line: line
      start: posOnLine - lexeme count end: posOnLine//lexeme count

    // tok debug
    pos <- readPos
    ^ tok
  ]

  on nextToken -> Token! = [
    .skipWhiteSpaces
    .skipComments


    // |ch
    // | '/' => .stepMatch: '/',
    //   ifTrue:  [
    //     "skipped line $line" echo
    //     .skipCurrentLine
    //   ]
    //   ifFalse: [
    //     ^.createToken: TokenType.BinarySymbol lexeme: "/"
    //     Unit
    //   ]


    l = ch toString


    tok = | ch
    | '\u0000' => [
      ^.createToken: TokenType.EndOfFile lexeme: l]
    | '=' => [
      .step
      | ch
      | '=' => .createToken: TokenType.BinarySymbol lexeme: "=="
      | '>' => .createToken: TokenType.Then lexeme: "=>"
      |=> .createToken: TokenType.Assign lexeme: "="
    ]

    | '|' => [
      .step
      | ch
      | '=' => [
        .step
        | ch
        | '>' => .createToken: TokenType.Else lexeme: "|=>"
        |=> Error throwWithMessage: "expected |=>"
      ]
      | '|' => .createToken: TokenType.BinarySymbol lexeme: "||"
      |=> .createToken: TokenType.If lexeme: "|"
    ]

    | '"' => [
      result = .parseStringLike: '"'
      ^ .createToken: TokenType.String lexeme: result
    ]
    | '\'' => [
      result = .parseStringLike: '\''
      ^ .createToken: TokenType.Char lexeme: result
    ]
    // | '/' => .stepMatch: '/',
    //   ifTrue:  [
    //     .skipCurrentLine
    //     .createToken: TokenType.Comment lexeme: "//"
    //   ]
    //   ifFalse: [.createToken: TokenType.BinarySymbol lexeme: "/"]

    | '/' => .createToken: TokenType.BinarySymbol lexeme: l


    | '!' => .stepMatch: '=',
      ifTrue:  [.createToken: TokenType.BinarySymbol lexeme: "!="]
      ifFalse: [.createToken: TokenType.Bang lexeme: "!"]
    | '&' => .stepMatch: '&',
      ifTrue:  [.createToken: TokenType.BinarySymbol lexeme: "&&"]
      ifFalse: [.createToken: TokenType.Ampersand lexeme: "&"]

    // parens
    | '(' => .createToken: TokenType.OpenParen   lexeme: l
    | ')' => .createToken: TokenType.CloseParen  lexeme: l
    | '[' => .createToken: TokenType.OpenBracket   lexeme: l
    | ']' => .createToken: TokenType.CloseBracket  lexeme: l
    | '{' => .createToken: TokenType.OpenBrace   lexeme: l
    | '}' => .createToken: TokenType.CloseBrace  lexeme: l
    | '#' => [
      .step
      | ch
      | '{' => .createToken: TokenType.OpenBraceHash lexeme: "#{"
      | '(' => .createToken: TokenType.OpenParenHash lexeme: "#("
      |=> Error throwWithMessage: "only { or ( can be after #"
    ]


      // binary symbols and negative digits
    | '-' => ^ .peekChar isDigit ifTrue: [
      .step // skip minus
      lit = "-" + .parseNumber
      .createToken: TokenType.Integer lexeme: lit
    ] ifFalse: [
      .stepMatch: '>',
        ifTrue:  [.createToken: TokenType.ReturnArrow lexeme: "->"]
        ifFalse: [.createToken: TokenType.BinarySymbol lexeme: "-"]
    ]

    |'<' => .stepMatch: '=',
      ifTrue:  [.createToken: TokenType.BinarySymbol lexeme: "<="]
      ifFalse: [
        .match: '-',
          ifTrue:  [.createToken: TokenType.AssignArrow lexeme: "<-"]
          ifFalse: [.createToken: TokenType.BinarySymbol lexeme: "<"]


      ]

    |'>' => .stepMatch: '=',
      ifTrue:  [.createToken: TokenType.BinarySymbol lexeme: ">="]
      ifFalse: [.createToken: TokenType.BinarySymbol lexeme: ">"]


    |'+'|'*' => .createToken: TokenType.BinarySymbol lexeme: l
    // other staff
    | ',' =>     .createToken: TokenType.Comma lexeme: l
    | '.' =>     .createToken: TokenType.Dot lexeme: l
    | '^' => .createToken: TokenType.Return  lexeme: l

    |=> [
      // identifier
      ch isLetter || (ch == '_') ifTrue: [
        pos == readPos ifTrue: [
          pos <- pos dec
        ]
        lit = .readIdentifier
        tt = Token lookupKeyword: lit

        // digit after identifier "sas42"
        ch isDigit ifTrue: [
          litDigit = .parseNumber
          ^ .createToken: TokenType.Identifier lexeme: lit + litDigit
        ]

        // colon after identifier

        ^| ch
        | ':' => [
          .step
          | ch
          | ':' => [
            .step
            .createToken: TokenType.IdentifierDoubleColon lexeme: lit
          ]
          |=> .createToken: TokenType.IdentifierColon lexeme: lit
        ]
        | '?' => [
          .step
          .createToken: TokenType.NullableIdentifier lexeme: lit
        ]
        |=> [
          .createToken: tt lexeme: lit
        ]
      ]
      // digit
      ch isDigit ifTrue: [
        lit = .parseNumber
        ^ .createToken: TokenType.Integer lexeme: lit
      ]

      // fail
      .createToken: TokenType.Invalid lexeme: l
    ]

    .step
    ^ tok
  ]

  on lex -> mut List::Token! = [
    mut newTok = .nextToken orPANIC
    mut tokens::mut List::Token = {newTok}!

    [newTok kind != TokenType.EndOfFile] whileTrue: [
      newTok <- .nextToken
      tokens add: newTok
    ]
    ^ tokens
  ]
  /// skips any symbol until "\n"
  on skipCurrentLine = [
    [(ch != '\n') && (ch != '\u0000')] whileTrue: [
      // "'$ch'" echo
      .step
    ]
    .match: '\n', ifTrue: [
      line <- line inc
      posOnLine <- 0
    ]
  ]
]


enum StrMode = Single | Multi

/// assume that delimiter was already eaten
mut Lexer parseStringLike(delimiter): Char -> String = [
  mut mode = StrMode.Single
  localPos = pos

  .match: delimiter // eat the first "
  [ch != delimiter] whileTrue: [
    ch == '\n' ifTrue: [mode <- StrMode.Multi]
    .step
  ]
  .match: delimiter // eat the last "

  ^ input slice: localPos..<pos
]

mut Lexer readIdentifier -> String = [
  localPos = pos

  [ch isLetter] whileTrue: [
    .step
  ]

  result = input slice: localPos..<pos //readPos dec
  ^result
]

mut Lexer parseNumber -> String = [
  localPos = pos
  [ch isDigit] whileTrue: [
    .step
  ]

  result = input slice: localPos..<pos // readPos dec
  ^result
]

mut Lexer skipWhiteSpaces = [
  [(ch == ' ') || (ch == '\t') || (ch == '\n') || (ch == '\r')] whileTrue: [

    ch == '\n' ifTrue: [
      line <- line inc
      posOnLine <- 0
    ]
    .step

  ]

]

mut Lexer skipComments = [
  mut c = true

  [c] whileTrue: [
    .skipWhiteSpaces

    savePoint = readPos
    |ch
    | '/' => [
      .peekChar == '/',
        ifTrue: [
          .skipCurrentLine
        ]
        ifFalse: [
          c <- false
        ]
    ]
    |=> [
      c <- false
    ]
  ]
]
